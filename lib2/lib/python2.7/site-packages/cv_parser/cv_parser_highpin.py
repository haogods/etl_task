#!/usr/bin/env python
# coding=utf-8

import sys,re,codecs
from bs4 import BeautifulSoup
from urllib2 import urlopen
from collections import OrderedDict
from base import CvTopParser
import os
reload(sys)
sys.setdefaultencoding('utf-8')



#zhangzq 20160314
class CvParserHighPin(CvTopParser):
    """
    对卓聘的简历进行解析
    """
    def __init__(self):

        CvTopParser.__init__(self)

        self.PAY = re.compile(u"(\d+[\s\-])?\d+元")
        self.UPDATETIME = re.compile("更新日期[:：\s](\d+年\d+月\d+日)")
        self.ADDR = re.compile(u"现居住地[：:\s](\S+)")



    def preprocess(self,htmlContent=None,fname=None,url=None):
        if url!=None:
            self.html= urlopen(url).read().decode('utf-8')
        elif htmlContent:
            self.html = htmlContent
        elif fname:
            self.html = codecs.open(fname,'rb','utf-8').read()
        else:
            raise Exception("input error")

        if re.search(u"已被(求职者)?删除|无法查看",self.html):
            raise Exception("error: input illegal cv ")

        self.soup = BeautifulSoup(self.html,"lxml")
        self.resume = self.soup.find('div',{"class":"detailbox clearfix"})

        self.basic_soup= self.soup.find('div',{"class":"resume-basic"})
        self.user_detail_soup =self.soup.find('div',{"class":"detail-con clearfix"})
        self.detail_tab_soup = self.soup.find('div',{"class":"detail-tabs-new"})

        self.refresh()
        self.result["cvFrom"] = "highpin"
        


    # 解析基本信息
    def regular_basic(self):

        res = OrderedDict()
        res_private = OrderedDict()
        #最近登陆时间
        find_update_time = self.basic_soup.find("span",{"class":"update"})
        self.result['baseInfo']["updateTime"] = find_update_time.get_text()[7:].strip() if find_update_time else ""
        #简历ID
        find_cv_id = self.user_detail_soup.find("div","resume")
        self.result['baseInfo']["cvId"] = find_cv_id.get_text()[5:].strip() if find_cv_id else ""

        find_user_info = self.user_detail_soup.find_all("li")
        if len(find_user_info)<5:
            return
        tags = find_user_info[0].get_text().strip().split(u'|')
        if len(tags)==4:
            #姓名
            self.result['privateInfo']["userName"] =tags[0][3:].strip()
            #性别
            self.result['baseInfo']["gender"] = tags[1].strip()
            #多少年工作经验
            self.result['baseInfo']["nowWorkAge"] = tags[2].strip()
            #学历
            self.result['baseInfo']["nowDiploma"]=tags[3].strip()
        #信用
        self.result['baseInfo']["credit"] = find_user_info[1].get_text()[3:].strip()

        tags = find_user_info[2].get_text().strip().split(u'|')
        if len(tags)==4:
            #岁数
            self.result['baseInfo']["age"] = tags[0].strip()
            #出生年月
            self.result['baseInfo']["dob"] = tags[1].strip()
            #婚姻
            self.result['baseInfo']["marriage"]=tags[2].strip()
            #地点
            self.result['baseInfo']["nowAddress"] = tags[3].strip()
        self.result['privateInfo']["phone"]  = find_user_info[3].get_text()[3:].strip()
        self.result['privateInfo']["email"]  = find_user_info[4].get_text()[3:].strip()


        #简历标签
        tagsoup = self.detail_tab_soup.find("div",{"class":"new-border-bottom addBottompad clearfix pb_8"})
        if tagsoup and re.search(u"简历标签",tagsoup.find("h4").get_text()):
            tags = [li.get_text().strip() for li in tagsoup.find_all("li")]
            self.result['privateInfo']['keyWords']='\n'.join(tags)

        #目前状态
        now_state_soup = ""
        for field in self.detail_tab_soup.find_all("div",{"class":"new-border-bottom"}):
            if field.find("h4") and re.search(u"目前状态",field.find("h4").get_text()):
                now_state_soup = field
                break
        if now_state_soup:
            rows = field.find_all("div",{"class":"detail-lists clearfix"})
            for row in rows:
                if re.search(u"目前工作状态",row.find("div",{"class":"detail-lables-statusgoal"}).get_text()):
                    self.result['jobExp']["workStatus"] = row.find("div",{"class":"detail-cons"}).get_text()
                elif re.search(u"目前薪资",row.find("div",{"class":"detail-lables-statusgoal"}).get_text()):
                    self.result['baseInfo']["nowSalary"] = row.find("div",{"class":"detail-cons"}).get_text()




    # 求职意向
    def regular_expect(self):

        expsoup = ""
        for field in self.detail_tab_soup.find_all("div",{"class":"new-border-bottom"}):
            if field.find("h4") and re.search(u"职业意向",field.find("h4").get_text()):
                expsoup = field
                break


        if expsoup:
            rows= expsoup.find_all("div",{"class":"detail-lists clearfix"})
            for row in rows:
                if re.search(u"期望从事行业",row.get_text()):
                    self.result['jobExp']["expIndustrys"] = row.find("div",{"class":"detail-cons"}).get_text()
                if re.search(u"期望职业",row.get_text()):
                    self.result['jobExp']["expPositions"] = row.find("div",{"class":"detail-cons"}).get_text()
                if re.search(u"期望工作地点",row.get_text()):
                    self.result['jobExp']["expLocations"] = row.find("div",{"class":"detail-cons"}).get_text()
                if re.search(u"期望薪资",row.get_text()):
                    self.result['jobExp']["expSalary"] = row.find("div",{"class":"detail-cons"}).get_text()

    # 教育经历
    def regular_educate(self):

        edusoup = ""
        for field in self.detail_tab_soup.find_all("div",{"class":"detail-mar"}):
            if field.find("h4") and re.search(u"教育背景",field.find("h4").get_text()):
                edusoup = field
                break


        res = []
        id=1
        #只有一条教育经历
        if edusoup:
            tmp = self.get_eduDict()
            tags = edusoup.find("h5").get_text('|')
            tags = re.split(u"--|\|",tags)
            tmp["itemId"] = str(id)
            tmp["eduStart"] = self.clean_edu_time(tags[0])
            tmp["eduEnd"] = self.clean_edu_time(tags[1])
            tmp["schName"] = tags[2].strip()
            rows = edusoup.find_all("div",{"class":"detail-lists-two clearfix"})
            for row in rows:
                if re.search(u"专业名称",row.get_text()):
                    tmp["majorName"] = row.find("div",{"class":"detail-cons2"}).get_text()
                elif re.search(u"学历/学位",row.get_text()):
                    tmp["eduDiploma"] = row.find("div",{"class":"detail-cons2"}).find_next("span").get_text()
                    tmp["eduTongZhao"] = re.sub(u"全日制统招：",'',row.find("div",{"class":"detail-cons2"}).find_next("span").find_next("span").get_text()) if \
                        row.find("div",{"class":"detail-cons2"}).find_next("span").find_next("span") else ""
            res.append(tmp)

        self.result['eduList'] = res




    #　工作经历
    def regular_workexp(self):
        
        worksoup = ""
        for field in self.detail_tab_soup.find_all("div",{"class":"detail-mar"}):
            if field.find("h4") and re.search(u"工作经验",field.find("h4").get_text()):
                worksoup = field
                break
        res=[]
        id=1
        rows = worksoup.find_all("h5")
        for row in rows:
            tmp=self.get_jobDict()
            tags = row.get_text("|").split('|')
            if len(tags)==9:
                tmp["itemId"] = str(id)
                tmp["jobStart"] = self.clean_edu_time(tags[0].split(u'--')[0].strip())
                tmp["jobEnd"] = self.clean_edu_time(tags[0].split(u'--')[1].strip())
                tmp["incName"] = tags[2].strip()
                tmp["jobPosition"] = tags[5].strip()
                tmp["jobDuration"] = tags[7].strip()[1:-1]
            next_tags=[]
            while True:
                if row.next_sibling.next_sibling and row.next_sibling.next_sibling.name=='div':
                    next_tags.append(row.next_sibling.next_sibling)
                    row=row.next_sibling.next_sibling
                else:
                    break
            for nt in next_tags:
                if re.search(u"所属行业",nt.find('div',{"class":"detail-lables"}).get_text()):
                    tmp["incIndustrys"] = nt.find('div',{"class":"detail-cons2"}).get_text().strip()
                elif re.search(u"公司性质",nt.find('div',{"class":"detail-lables"}).get_text()):
                    tmp["incType"] = nt.find('div',{"class":"detail-cons2"}).get_text().strip()
                elif re.search(u"公司规模",nt.find('div',{"class":"detail-lables"}).get_text()):
                    tmp["incEmployee"] = nt.find('div',{"class":"detail-cons2"}).get_text().strip()
                elif re.search(u"职位月薪",nt.find('div',{"class":"detail-lables"}).get_text()):
                    tmp["jobSalary"] = nt.find('div',{"class":"detail-cons2"}).get_text().strip()
                elif re.search(u"职责描述",nt.find('div',{"class":"detail-lables"}).get_text()):
                    tmp["jobDesc"] = nt.find('div',{"class":"detail-cons2"}).get_text().strip()
            id+=1
            res.append(tmp)
        self.result['jobList'] = res


    # 语言技能
    def regular_language(self):
         
        langsoup = ""
        for field in self.detail_tab_soup.find_all("div",{"class":"detail-mar"}):
            if field.find("h6") and re.search(u"语言能力",field.find("h6").get_text()):
                langsoup = field
                break

        res=[]
        id=1
        rows= langsoup.find_all("div",{"class":"diffent-cons add-con-bor"}) if langsoup else  []
        for row in rows:
            tmp=self.get_languageDict()
            items = re.sub(u'\s+',' ',row.get_text().strip()).split()
            tmp["itemId"] = str(id)
            tmp["languageName"] = items[0].strip()[3:]
            tmp["languageLevel"] = ' '.join(items[1:])
            id+=1
            res.append(tmp)
        self.result["languageList"] = res


    #　证书
    def regular_cert(self):
        

        certsoup =""
        for field in self.field_list:
            if field.find("h3") and re.search(u"证书",field.find("h3").get_text()):
                certsoup = field
                break

        res = []
        id = 1
        if certsoup:
            items = certsoup.find_all("h2")
            for item in items:
                tokens = item.get_text().split()
                if len(tokens)<2:continue
                tmp=self.get_certDict()
                tmp["itemId"] = str(id)
                tmp["certTime"] = tokens[0].strip()
                tmp["certName"] = tokens[1].strip()
                
                if item.find_next_sibling("div","resume-preview-dl"):
                    cert_str = item.find_next_sibling("div").find_all("td")[-1].get_text()
                else:
                    cert_str = tokens[1]

                find_level = self.CERT_LEVEL.search(cert_str)
                tmp["certLevel"] = find_level.group() if find_level else "None"

                res.append(tmp)
                id += 1

        if not certsoup and self.jd_type == 3:
            for field in self.field_list:
                if re.search(u"证书",field.get_text()):
                    certsoup = field.find_next("dd")
                    items = certsoup.find_all("div","certificates")
                    id = 1
                    for item in items:
                        tmp = self.get_certDict()
                        tmp["itemId"] = str(id)
                        tmp["certTime"] = item.find("p").get_text(strip=True)
                        tmp["cerName"] = item.find("h6").get_text(strip=True)
                        res.append(tmp)
                        id += 1
                    break                        

        self.result["certList"] = res
   
    
    # 技能
    def regular_skill(self):
        """
        技能模块
        """

        skillsoup = ""
        for field in self.field_list:
            if field.find("h3") and re.search(u"技能",field.find("h3").get_text()):
                skillsoup = field
                break
        res = []
        id =1
        if skillsoup:
            if self.NONAME:
                items = skillsoup.get_text().split("\n")
            else:
                items = skillsoup.get_text().split("\n")

            for item in items:
                tokens = [token for token in re.split(u"[:：| ]",item) if len(token.strip())>1]
                if len(tokens)<2:continue
                tmp = self.get_skillDict()
                tmp["itemId"] = str(id)
                tmp["skillName"] = tokens[0].strip()
                tmp["skillLevel"] = tokens[1].strip()
                find_duration = re.search("\d+月|[半一二三四五六七八九十\d]年",item)
                tmp["skillDuration"] = find_duration.group() if find_duration else "None"
                res.append(tmp)
                id += 1
        
        if not skillsoup and self.jd_type == 3:
            for field in self.field_list:
                if re.search(u"专业技能",field.get_text()):
                    skillsoup = field.find_next("dd")
                    items = skillsoup.find_all("div","professional-skill")
                    for item in items:
                        tmp = self.get_skillDict()
                        tmp["itemId"] = str(id)
                        tokens = item.get_text(strip=True).split(u"|")
                        if len(tokens)>1:
                            tmp["skillName"] = tokens[0]
                            tmp["skillLevel"] = tokens[1]
                            if len(tokens)>2:
                                tmp["skillDuration"] = tokens[2]
                        res.append(tmp)
                        id += 1
                    break

        self.result['skillList'] = res

     
    #　项目经验
    def regular_project(self):


        prosoup = ""
        for field in self.detail_tab_soup.find_all("div",{"class":"detail-mar"}):
            if field.find("h4") and re.search(u"项目经验",field.find("h4").get_text()):
                prosoup = field
                break
        res=[]
        id=1
        rows = prosoup.find_all("h5") if prosoup else  []
        for row in rows:
            tmp=self.get_proDict()
            tags = row.get_text("--").split('--')
            if len(tags)==3:
                tmp["itemId"] = str(id)
                tmp["proStart"] = tags[0].strip()
                tmp["proEnd"] = tags[1].strip()
                tmp["proName"] = tags[2].strip()
            next_tags=[]
            while True:
                if row.next_sibling.next_sibling and row.next_sibling.next_sibling.name=='div':
                    next_tags.append(row.next_sibling.next_sibling)
                    row=row.next_sibling.next_sibling
                else:
                    break
            for nt in next_tags:
                if re.search(u"项目描述",nt.find('div',{"class":"detail-lables"}).get_text()):
                    tmp["proDesc"] = nt.find('div',{"class":"detail-cons2"}).get_text().strip()
                elif re.search(u"项目职责",nt.find('div',{"class":"detail-lables"}).get_text()):
                    tmp["proDuty"] = nt.find('div',{"class":"detail-cons2"}).get_text().strip()

            id+=1
            res.append(tmp)
        self.result['proList'] = res



    def regular_train(self):

        trainsoup = ""
        for field in self.field_list:
            if field.find("h3") and re.search(u"培训经历",field.find("h3").get_text()):
                trainsoup = field
                break

        res = []
        id = 1
        if trainsoup:
            items = trainsoup.find_all("h2")
            for item in items:
                tokens = [ token for token in item.get_text().split() if len(token.strip())>1 ]
                if len(tokens)<3:continue

                tmp = self.get_trainDict()
                tmp["itemId"] = str(id)
                tmp["trainStart"] = tokens[0]
                tmp["trainEnd"] = tokens[1]
                tmp["trainTitle"] = "".join(tokens[2:])

                field_list = item.find_next("table").find_all("td")
                for field in field_list:
                    find_agency = re.search(u"培训机构：",field.get_text())
                    find_location = re.search(u"培训地点",field.get_text())
                    find_desc = re.search(u"培训描述",field.get_text())
                    find_content = re.search(u"培训内容",field.get_text())
                    find_cert = re.search(u"所获证书",field.get_text())

                    if find_agency:
                        tmp["trainAgency"] = field.find_next_sibling("td").get_text() if field.find_next_sibling("td") else "None"

                    elif find_location:
                        tmp["trainLoc"] = field.find_next_sibling("td").get_text() if field.find_next_sibling("td") else "None"

                    elif find_desc:
                        tmp["trainDesc"] = field.find_next_sibling("td").get_text() if field.find_next_sibling("td") else "None"
                    
                    elif find_cert:
                        tmp["trainCert"] = field.find_next_sibling("td").get_text() if field.find_next_sibling("td") else "None"
                    
                    elif find_content:
                        tmp["trainContent"] = field.find_next_sibling("td").get_text() if field.find_next_sibling("td") else "None"

                res.append(tmp)
                id += 1

        if not trainsoup and self.jd_type == 3:
            for field in self.field_list:
                if re.search(u"培训经历",field.get_text()):
                    trainsoup = field.find_next("dd")
                    items = trainsoup.find_all('div',"training")
                    for item in items:
                        tmp = self.get_trainDict()
                        tmp["itemId"] = str(id)
                        tokens = item.find("p").get_text(strip=True).split("--")
                        tmp["trainStart"] = self.clean_edu_time( tokens[0])
                        tmp["trainEnd"] = self.clean_edu_time(tokens[1])
                        tmp["trainAgency"] = item.find("h6").get_text(strip=True)
                        tags = item.find_all("strong")
                        for tag in tags:
                            if re.search(u"培训课程",tag.get_text()):
                                tmp["trainTitle"] = tag.find_parent("div").get_text(strip=True).split("：",1)[-1]
                            if re.search(u"所获证书",tag.get_text()):
                                tmp["trainCert"] = tag.find_parent("div").get_text(strip=True).split("：",1)[-1]
                            if re.search(u"培训地点",tag.get_text()):
                                tmp["trainLoc"] = tag.find_parent("div").get_text(strip=True).split("：",1)[-1]
                            if re.search(u"培训描述",tag.get_text()):
                                tmp["trainDesc"] = tag.find_parent("div").get_text(strip=True).split("：",1)[-1]
                            if re.search(u"培训内容",tag.get_text()):
                                tmp["trainContent"] = tag.find_parent("div").get_text(strip=True).split("：",1)[-1]
                        res.append(tmp)
                        id += 1
                    break

        self.result["trainList"] = res

    
    def regular_private(self):
        """
        身份证号，联系电话等隐私信息
        """
        
        base_info = self.resume.find("div","summary").get_text()
        
        find_phone = self.PHONE.search(base_info)
        find_email = self.EMAIL.search(base_info)
        find_qq = self.QQ.search(base_info)
        find_idNum = self.IDNUM.search(base_info)

        if not self.NONAME and self.jd_type!=3:
            self.result["privateInfo"]["userName"] = self.resume.find("div","resume-preview-main-title").find("div","main-title-fl").get_text().strip()
        self.result["privateInfo"]["phoneNumber"] = find_phone.group(1) if find_phone else ""
        self.result["privateInfo"]["email"] = find_email.group(1) if find_email else ""
        self.result["privateInfo"]["qq"] = find_qq.group(1) if find_qq else ""
        self.result["privateInfo"]["idNumber"] = find_idNum.group(1) if find_idNum else ""




    def regular_other(self):


        for field in self.detail_tab_soup.find_all("div",{"class":"detail-mar"}):
            if field.find("h4") and re.search(u"自我评价",field.find("h4").get_text()):
                self.result["others"]['selfIntro']=field.find("p").get_text()

    def parser(self,htmlContent=None,fname=None,url=None):
        self.preprocess(htmlContent,fname,url)
        self.regular_basic()
        # self.regular_private()
        self.regular_expect()
        self.regular_educate()
        self.regular_workexp()
        # self.regular_skill()
        # self.regular_cert()
        self.regular_language()
        self.regular_project()
        # self.regular_train()
        self.regular_other()
        return self.result


    
    def output(self):
        res = "\n"
        for k in self.result:
            res += k+":"+"\n"
            if isinstance(self.result[k],dict):
                for kk,vv in self.result[k].iteritems():
                    res += '%1s: %s\n' %( kk,vv )
            elif isinstance(self.result[k],list):
                for i,exp in enumerate(self.result[k]):
                    res+= "%12s\n" % (str(i+1))
                    if isinstance(exp,dict):
                        for kk,vv in exp.iteritems():
                            res += "%22s: %s\n" % (kk,vv)
                    elif isinstance(exp,tuple):
                        for kk in exp:
                            res += '%22s \n'% (kk)
                    res += " "*10+'---'*10+'\n'
            else:
                res += " "*10+"%s\n" % (self.result[k])
        return res




import simplejson as json

if __name__ == "__main__":
    """
    测试
    """
    test = CvParserHighPin()
#     path = './data/cv_zhilian/'
#     fnames = [ path+fname for fname in os.listdir(path)][:10]
#
#     for i,fname in enumerate(fnames):
#         try:
#             print i+1,'='*20,fname
#             htmlContent = codecs.open(fname,'rb','utf-8').read()
#             result = test.parser(htmlContent)
#             output = test.output()
#             print(json.dumps(result,ensure_ascii=False,indent=4))
#             json.dump(result,open("output_cv_zhilian.json",'wb'))
# #            print output
#         except Exception,e:
#             print e
#             continue
#
    with open('/home/zhangzq/下载/卓聘CV 样本.html') as fr:
        lines= fr.readlines()

    htmlContent ='\n'.join(lines)
    result = test.parser(htmlContent)
    print json.dumps(result,ensure_ascii=False,indent=4)


